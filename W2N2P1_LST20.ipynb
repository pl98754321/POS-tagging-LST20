{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pl98754321/POS-tagging-LST20/blob/main/W2N2P1_LST20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvCXZ4adn17r"
      },
      "source": [
        "# initial Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajnqk0M4w8jV"
      },
      "outputs": [],
      "source": [
        "! pip install -qq datasets transformers[sentencepiece] simpletransformers\n",
        "! pip install -qq simpletransformers\n",
        "#Data management\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import cv2\n",
        "import re\n",
        "import string\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "#Model management\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import torch\n",
        "import joblib\n",
        "from ast import literal_eval\n",
        "\n",
        "#data visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "\n",
        "#torch\n",
        "import torch as T\n",
        "import torch.nn as N\n",
        "import torch.optim as O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht6cAX3sv8Xh",
        "outputId": "50f8be12-81a7-46e0-efc1-2b03ecd5f39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 20 11:53:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    42W / 250W |   1583MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMWB0hysnyt7"
      },
      "source": [
        "# get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghSmqdzBX6TW"
      },
      "source": [
        "LST20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMDULqK4n49J"
      },
      "outputs": [],
      "source": [
        "! wget https://github.com/kobkrit/datasets/raw/main/AIFORTHAI-LST20Corpus.tar.gz\n",
        "! tar -xvzf /content/AIFORTHAI-LST20Corpus.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuwJ8--TiwWz"
      },
      "source": [
        "# get Embedding layer From HuggingFace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmdLMv8ZjDoJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForTokenClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased')\n",
        "model_hug = AutoModelForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased',\n",
        "                                                            revision='finetuned@lst20-pos')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaKGYJEEi4yn"
      },
      "outputs": [],
      "source": [
        "word_em_initial = model_hug.roberta.embeddings.word_embeddings.weight.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1ekT_5CYRef"
      },
      "outputs": [],
      "source": [
        "np_emb_weight = model_hug.roberta.embeddings.word_embeddings.weight.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNleQDPgvt5R",
        "outputId": "7b6c028c-cff8-4d42-a1fe-20917fade786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='airesearch/wangchanberta-base-att-spm-uncased', vocab_size=25005, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True), 'additional_special_tokens': ['<s>NOTUSED', '</s>NOTUSED', '<_>']})"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict_word2int = tokenizer.vocab # ไว้ใช่้สำหรับแปลง คำเป็ลเลข\n",
        "vocal_all = list(dict_word2int.keys()) #ใช้สำหรับตรวจคำ\n",
        "vocab_len = word_em_initial.shape[0] # 25005\n",
        "emb_dim =  word_em_initial.shape[1] # 768\n",
        "tokenizer #token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "070bIL1I1pcl"
      },
      "source": [
        "# Func Batchsize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOkpFYPzg-GD"
      },
      "outputs": [],
      "source": [
        "dict_word2int = tokenizer.vocab # ไว้ใช่้สำหรับแปลง คำเป็ลเลข\n",
        "vocab_len = word_em_initial.shape[0] # 25005\n",
        "emb_dim =  word_em_initial.shape[1] # 768\n",
        "tokenizer #token\n",
        "\n",
        "# loop map ค่าใน dict\n",
        "def endcode_word(word):\n",
        "  if word==\" \": #clear ช่องว่างออกก่อน\n",
        "    return 10\n",
        "\n",
        "  elif word in dict_word2int: #ถ้าเจอใน ditionnary\n",
        "    return dict_word2int[word]\n",
        "\n",
        "  # else:\n",
        "  #   return 3\n",
        "\n",
        "  else: # ถ้าไม่เจอใน dictionary ก็ค่อยตัดคำ\n",
        "    for i in tokenizer(word)[\"input_ids\"]:\n",
        "      if i not in [5,6,10]:\n",
        "        return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2JDUkHBMWWh"
      },
      "outputs": [],
      "source": [
        "def encode_label(text) :\n",
        "  payload = {'NN' : 0, 'VV' : 1, 'CC' :2, 'PU' : 3, 'PS' : 4, 'AX' : 5, 'AV' : 6, 'FX' : 7, 'NU' : 8, 'AJ' : 9, 'CL' : 10, 'PR' : 11, 'NG' : 12, 'PA' :13, 'XX' :14, 'IJ' :15}\n",
        "  return payload[text]\n",
        "def decode_label(text) :\n",
        "  payload =   {0: \"NN\",1: \"VV\",3: \"CC\",2: \"PU\",4: \"PS\",5: \"AX\",6: \"AV\",7: \"FX\",8: \"NU\",9: \"AJ\",10: \"CL\",11: \"PR\",12: \"NG\",13: \"PA\",14: \"XX\",15: \"IJ\"}\n",
        "  return payload[text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqwSiHWRfwyJ"
      },
      "outputs": [],
      "source": [
        "_NER_TAGS = [\"O\",\"B_BRN\",\"B_DES\",\"B_DTM\",\"B_LOC\",\"B_MEA\",\"B_NUM\",\"B_ORG\",\"B_PER\",\"B_TRM\",\"B_TTL\",\"I_BRN\",\"I_DES\",\"I_DTM\",\"I_LOC\",\"I_MEA\",\"I_NUM\",\"I_ORG\",\"I_PER\",\"I_TRM\",\"I_TTL\",\"E_BRN\",\"E_DES\",\"E_DTM\",\"E_LOC\",\"E_MEA\",\"E_NUM\",\"E_ORG\",\"E_PER\",\"E_TRM\",\"E_TTL\",]\n",
        "list_index = range(len(_NER_TAGS))\n",
        "encode_NER_dict = dict(zip(_NER_TAGS,list_index))\n",
        "decode_NER_dict = dict(zip(list_index,_NER_TAGS))\n",
        "def encode_NER(word):\n",
        "  if word in _NER_TAGS:\n",
        "    return encode_NER_dict[word]\n",
        "  return len(_NER_TAGS)\n",
        "def decode_NER(num):\n",
        "  if len(_NER_TAGS) == num:\n",
        "    return \"UNK\"\n",
        "  return decode_NER_dict[num]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([\"a\",\"b\",\"c\"])\n",
        "d = np.array([1,2,3])\n",
        "\n",
        "for i,j in a,d:\n",
        "  print(i)\n",
        "  print(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "BJ60dqJLQh3T",
        "outputId": "e258debb-5428-4d07-bb82-b6ef5e9e8a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-23975b51412b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TClt0gRwYXsC"
      },
      "outputs": [],
      "source": [
        "class get_data():\n",
        "  def preprocessing(self,x,encode_dict,word=False):\n",
        "    words_payload_encoded = [encode_dict(r) for r in tqdm(x)]\n",
        "    np_word_encoded = np.array(words_payload_encoded)\n",
        "\n",
        "    batched_word = np_word_encoded[:-1*(np_word_encoded.shape[0]%self.BATCH_SIZE)].reshape(-1,self.BATCH_SIZE)\n",
        "\n",
        "    batched_word = batched_word.astype('float32')\n",
        "\n",
        "    return batched_word\n",
        "\n",
        "  def ADD_NER(self):\n",
        "    self.NER = self.preprocessing(self.df[\"NER\"].to_list(),encode_NER)\n",
        "    \n",
        "  def __init__(self,df,TAG,BATCH_SIZE):\n",
        "    self.df = df\n",
        "    self.BATCH_SIZE = BATCH_SIZE\n",
        "    self.x = self.preprocessing(df[\"words\"].to_list(),endcode_word,word=True)\n",
        "    self.y = self.preprocessing(df[TAG].to_list(),encode_label)\n",
        "    self.train = [[word,NER] for word,NER in ]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  def __getitem__(self):\n",
        "    return self.x , self.y\n",
        "\n",
        "  def "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ5X4PAzghYG"
      },
      "outputs": [],
      "source": [
        "class set_model():\n",
        "  def __init__(self,model,train_get_data,val_get_data):\n",
        "    self.model = model\n",
        "    self.train = train_get_data\n",
        "    self.val = val_get_data\n",
        "\n",
        "  def train(self):\n",
        "    ES = EarlyStopping(monitor='val_loss', patience=5, verbose=1,min_delta=0,restore_best_weights=True)\n",
        "    self.model.fit(self.train.x,self.train.y, \n",
        "                   epochs=100,\n",
        "                   validation_data=(self.val.x,self.val.x),\n",
        "                   callbacks = [ES],\n",
        "                   batch_size = 64)\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzbbZIkTqS2H"
      },
      "outputs": [],
      "source": [
        "def LST20_list(path = '/content/LST20_Corpus/test/*'):\n",
        "  sentense_payload = []\n",
        "  words_payload = []\n",
        "  POS_payload = []\n",
        "  NER_payload = []\n",
        "  index = 0\n",
        "  for i in glob.glob(path) :\n",
        "    fp = open(i,\"r\")\n",
        "    for line in fp.readlines() :\n",
        "      if line == '\\n' :\n",
        "        continue\n",
        "      else :\n",
        "        data_ = line[:-2].split(\"\\t\")\n",
        "        sentense_payload.append(index)\n",
        "        words_payload.append(data_[0])\n",
        "        POS_payload.append(data_[1])\n",
        "        NER_payload.append(data_[2])\n",
        "    index +=1\n",
        "  return pd.DataFrame(\n",
        "      {\"sentence_id\": sentense_payload, \"words\": words_payload, \"POS\": POS_payload,\"NER\":NER_payload}\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IdkyaBor0OL"
      },
      "source": [
        "นี่คือการทดลองทำ Batch 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx1IJRKTr4je"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlHJIEZyefFi"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L4id3XkfIaX"
      },
      "source": [
        "## data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQBByvxeaaHa"
      },
      "outputs": [],
      "source": [
        "train_df = LST20_list(path = '/content/LST20_Corpus/train/*')\n",
        "train_data = get_data(train_df,\n",
        "                      \"POS\",\n",
        "                      BATCH_SIZE)\n",
        "train_data.ADD_NER()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irVspasjZuSR"
      },
      "outputs": [],
      "source": [
        "val_df = LST20_list(path = '/content/LST20_Corpus/eval/*')\n",
        "val_data = get_data(val_df,\n",
        "                    \"POS\",\n",
        "                    BATCH_SIZE)\n",
        "val_data.ADD_NER()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNTrIlV6Z5wc"
      },
      "outputs": [],
      "source": [
        "test_df = LST20_list(path = '/content/LST20_Corpus/test/*')\n",
        "test_data = get_data(test_df,\n",
        "                    \"POS\",\n",
        "                    BATCH_SIZE)\n",
        "test_data.ADD_NER()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6g2JnWni1nx"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW36uuw-xno5"
      },
      "outputs": [],
      "source": [
        "vocab_len = word_em_initial.shape[0] # 25005\n",
        "emb_dim =  word_em_initial.shape[1] \n",
        "unique_y = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z18S20e5xNxK"
      },
      "outputs": [],
      "source": [
        "def LSTM_NER(vocab_len,emb_dim):\n",
        "    WORD_inputs = layers.Input(shape=(BATCH_SIZE))\n",
        "    NER_inputs = layers.Input(shape=(BATCH_SIZE))\n",
        "    WORD_emb = layers.Embedding(trainable=False,input_dim = vocab_len, output_dim = emb_dim ,name=\"emb1\")(WORD_inputs)\n",
        "    NER_emb = layers.Embedding(trainable=True,input_dim = 40, output_dim = 768 ,name=\"emb2\")(NER_inputs)\n",
        "    chunk = tf.concat([WORD_emb,NER_emb],axis=2)\n",
        "    blstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout = 0.2))(chunk)\n",
        "    blstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout = 0.2))(blstm)\n",
        "    x = layers.TimeDistributed(layers.Dense(128, activation = 'relu'))(blstm)\n",
        "    x = layers.TimeDistributed(layers.Dense(128, activation = 'relu'))(x)\n",
        "    x = layers.TimeDistributed(layers.Dense(unique_y, activation = 'softmax'))(x)\n",
        "\n",
        "    act_model = Model([WORD_inputs,NER_inputs], x)\n",
        "    act_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    print(act_model.summary())\n",
        "    return act_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0bVLWQ7y4aB",
        "outputId": "636f33b9-8573-4ddb-b6c2-013a334a5858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " emb1 (Embedding)               (None, 128, 768)     19203840    ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " emb2 (Embedding)               (None, 128, 768)     30720       ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat_3 (TFOpLambda)       (None, 128, 1536)    0           ['emb1[0][0]',                   \n",
            "                                                                  'emb2[0][0]']                   \n",
            "                                                                                                  \n",
            " bidirectional_6 (Bidirectional  (None, 128, 256)    1704960     ['tf.concat_3[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_7 (Bidirectional  (None, 128, 256)    394240      ['bidirectional_6[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_9 (TimeDistri  (None, 128, 128)    32896       ['bidirectional_7[0][0]']        \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " time_distributed_10 (TimeDistr  (None, 128, 128)    16512       ['time_distributed_9[0][0]']     \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " time_distributed_11 (TimeDistr  (None, 128, 16)     2064        ['time_distributed_10[0][0]']    \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,385,232\n",
            "Trainable params: 2,181,392\n",
            "Non-trainable params: 19,203,840\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = LSTM_NER(vocab_len,emb_dim)\n",
        "\n",
        "np_emb_weight = np_emb_weight.reshape(1,25005,768)\n",
        "model.get_layer(\"emb1\").set_weights(np_emb_weight) # use pretain weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R575WRIC2ujN",
        "outputId": "169c71c9-fbfc-4bdc-b8df-e6cf86228beb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0., ...,  0.,  0.,  4.],\n",
              "       [24.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       ...,\n",
              "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  5., ...,  0.,  0.,  0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "train_data.NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "w1J7menspSeO",
        "outputId": "b9d6119c-c89d-468d-d7b6-806e26180707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/332 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9638WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 64ms/step - loss: 0.1051 - accuracy: 0.9638\n",
            "Epoch 2/100\n",
            "331/332 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9649WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 62ms/step - loss: 0.1008 - accuracy: 0.9649\n",
            "Epoch 3/100\n",
            "331/332 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9656WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 63ms/step - loss: 0.0980 - accuracy: 0.9656\n",
            "Epoch 4/100\n",
            "331/332 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9664WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 64ms/step - loss: 0.0949 - accuracy: 0.9664\n",
            "Epoch 5/100\n",
            "331/332 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.9672WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 62ms/step - loss: 0.0923 - accuracy: 0.9672\n",
            "Epoch 6/100\n",
            "331/332 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9679WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 62ms/step - loss: 0.0898 - accuracy: 0.9679\n",
            "Epoch 7/100\n",
            "331/332 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 0.9682WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 62ms/step - loss: 0.0880 - accuracy: 0.9682\n",
            "Epoch 8/100\n",
            "332/332 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9689WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "332/332 [==============================] - 21s 63ms/step - loss: 0.0857 - accuracy: 0.9689\n",
            "Epoch 9/100\n",
            "100/332 [========>.....................] - ETA: 14s - loss: 0.0826 - accuracy: 0.9698"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-b653ebaf5fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0;31m#validation_data=([val_data.x,val_data.NER],val_data.y),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                    batch_size = 64)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ES = EarlyStopping(monitor='val_loss', patience=5, verbose=1,min_delta=0,restore_best_weights=True)\n",
        "model.fit([train_data.x,train_data.NER],train_data.y, \n",
        "                   epochs=100,\n",
        "                   #validation_data=([val_data.x,val_data.NER],val_data.y),\n",
        "                   callbacks = [ES],\n",
        "                   batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([val_data.x,val_data.NER],val_data.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VVTsvM2TRK1",
        "outputId": "e573bc5b-2b62-4769-ef0c-a37cd11603a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 5s 22ms/step - loss: 0.1029 - accuracy: 0.9637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1029287651181221, 0.9636579751968384]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict([test_data.x,test_data.NER])\n",
        "pred = pred.argmax(axis=2)"
      ],
      "metadata": {
        "id": "MclWFO2STnkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(pred.flatten(),test_data.y.flatten()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tAuDuKMTiXB",
        "outputId": "e8027c0b-f296-4031-8efb-0fe8c7c57efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.98      0.98     58310\n",
            "         1.0       0.97      0.95      0.96     43385\n",
            "         2.0       0.96      0.96      0.96     17631\n",
            "         3.0       1.00      1.00      1.00     37977\n",
            "         4.0       0.94      0.94      0.94     10946\n",
            "         5.0       0.95      0.93      0.94      7643\n",
            "         6.0       0.78      0.90      0.83      5820\n",
            "         7.0       0.99      1.00      0.99      6904\n",
            "         8.0       0.98      0.98      0.98      6260\n",
            "         9.0       0.86      0.90      0.88      4201\n",
            "        10.0       0.89      0.87      0.88      3834\n",
            "        11.0       0.90      0.81      0.85      2390\n",
            "        12.0       1.00      1.00      1.00      1687\n",
            "        13.0       0.90      0.73      0.80       241\n",
            "        14.0       0.00      0.00      0.00         0\n",
            "        15.0       0.50      0.67      0.57         3\n",
            "\n",
            "    accuracy                           0.96    207232\n",
            "   macro avg       0.85      0.85      0.85    207232\n",
            "weighted avg       0.97      0.96      0.96    207232\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTzWYUsdT5zk"
      },
      "source": [
        "# INPUT + NER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUbPOgqXUOKe"
      },
      "source": [
        "## data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnhfLprkeeMJ"
      },
      "outputs": [],
      "source": [
        "clean_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx5bwDVDU0Ny"
      },
      "outputs": [],
      "source": [
        "clean_train,clean_val = train_test_split(clean_data,train_size=0.95,stratify=clean_data[\"POS\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3yeDSUXehMN"
      },
      "outputs": [],
      "source": [
        "clean_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS4-5V_-UCkA"
      },
      "outputs": [],
      "source": [
        "new_data = get_data(list(clean_train[\"text\"]),list(clean_train[\"POS\"]),BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwlK1NStelMv"
      },
      "outputs": [],
      "source": [
        "clean_train[\"text\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV2IzmqEaIuF"
      },
      "outputs": [],
      "source": [
        "new_val = get_data(list(clean_val[\"text\"]),list(clean_val[\"POS\"]),BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Sew0NXbZ_IE"
      },
      "outputs": [],
      "source": [
        "clean_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBGK_-jpVa-c"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEo-ELuaVUR8"
      },
      "outputs": [],
      "source": [
        "def LSTM_new(vocab_len,emb_dim):\n",
        "    inputs_WORD = layers.Input(shape=(BATCH_SIZE))\n",
        "    inputs_NER = layers.Input(shape=(BATCH_SIZE))\n",
        "    Emb_word = layers.Embedding(trainable=False,input_dim = vocab_len, output_dim = emb_dim ,name=\"emb\")(inputs_WORD)\n",
        "    Emb_NER = layers.Embedding(trainable=True,input_dim = vocab_len, output_dim = emb_dim ,name=\"emb\")(inputs_NER)\n",
        "    concat = tf.concat([Emb_word,Emb_NER],axis=2)\n",
        "    blstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout = 0.2))(concat)\n",
        "    blstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout = 0.2))(blstm)\n",
        "    x = layers.TimeDistributed(layers.Dense(128, activation = 'relu'))(blstm)\n",
        "    x = layers.TimeDistributed(layers.Dense(128, activation = 'relu'))(x)\n",
        "    x = layers.TimeDistributed(layers.Dense(64, activation = 'relu'))(x)\n",
        "    x = layers.TimeDistributed(layers.Dense(unique_y, activation = 'softmax'))(x)\n",
        "\n",
        "    act_model = Model([inputs_WORD,inputs_NER], x)\n",
        "    act_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    print(act_model.summary())\n",
        "    return act_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC5q89w0VeYC"
      },
      "outputs": [],
      "source": [
        "vocab_len = word_em_initial.shape[0] # 25005\n",
        "emb_dim =  word_em_initial.shape[1] \n",
        "unique = train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzeD-jxwVce2"
      },
      "outputs": [],
      "source": [
        "model_NER  = LSTM_new(vocab_len,emb_dim)\n",
        "\n",
        "np_emb_weight = np_emb_weight.reshape(1,25005,768)\n",
        "model_new.get_layer(\"emb\").set_weights(np_emb_weight) # use pretain weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duYuXwIZhkXY"
      },
      "outputs": [],
      "source": [
        "LSTM_NER = set_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUzmUWEJ2KBy"
      },
      "source": [
        "# Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TakXgkU7bWl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9fNIYh2z9hv"
      },
      "source": [
        "# After Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJFGpp4Irorl"
      },
      "source": [
        "## Dowload True Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNaAA7CvsD_l"
      },
      "outputs": [],
      "source": [
        "!unzip /content/pos_test.txt.zip -d /content/submission/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjW6wb6OsI2O"
      },
      "outputs": [],
      "source": [
        "fp = open(\"/content/submission/pos_test.txt\",\"r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMf-LiOZsKon"
      },
      "outputs": [],
      "source": [
        "word_list_submission = []\n",
        "for line in fp.readlines() :\n",
        "  if line != '\\n' :\n",
        "    word_list_submission.append(line[:-1])\n",
        "  else :\n",
        "    word_list_submission.append('_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5bkLCU2sLhw"
      },
      "outputs": [],
      "source": [
        "word_list_submission = word_list_submission[:-1]\n",
        "len(word_list_submission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeS59MsgeYLr"
      },
      "outputs": [],
      "source": [
        "last_pad = BATCH_SIZE - (len(word_list_submission)%BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TQbFLJYsd0-"
      },
      "outputs": [],
      "source": [
        "word_list_submission += ['_']*last_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNkHPzaCsmIU"
      },
      "outputs": [],
      "source": [
        "word_list_submission_encoded = [endcode_word(r) for r in tqdm(word_list_submission)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wMkqnprsooQ"
      },
      "outputs": [],
      "source": [
        "np_word_list_submission_encoded_batched = np.array(word_list_submission_encoded).reshape(-1,BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAqZUWcKsstL"
      },
      "outputs": [],
      "source": [
        "np_word_list_submission_encoded_batched.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list_submission"
      ],
      "metadata": {
        "id": "mC60aYi3Szsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsdB8yHKs01G"
      },
      "source": [
        "## Predict True test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwbT9ibIs6wV"
      },
      "outputs": [],
      "source": [
        "z = model.predict(np_word_list_submission_encoded_batched).argmax(axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHkHOeAts90f"
      },
      "outputs": [],
      "source": [
        "func2_ = np.vectorize(lambda x : decode_label(x))\n",
        "z_decode = func2_(z)\n",
        "z_decode = z_decode.flatten()\n",
        "z_decode = z_decode.tolist()[:-last_pad]\n",
        "print(len(z_decode))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSLLDwdDthx1"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sok98k3Y3aAw"
      },
      "outputs": [],
      "source": [
        "!gdown --id 1mrbGe7J6nR1PZRGjCglZKugBghc_L-4_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b19_cgWtbEi"
      },
      "outputs": [],
      "source": [
        "submission_df = pd.read_csv(\"/content/pos_sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcT6LIUotcYY"
      },
      "outputs": [],
      "source": [
        "submission_df.Predicted = z_decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK919DZCtdCP"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv(\"submission.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIaYUokYtmeQ"
      },
      "outputs": [],
      "source": [
        "model.save('LSTM_emb_bert.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsaG-k3I7vBK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "W2N2P1_LST20.ipynb",
      "toc_visible": true,
      "provenance": [],
      "mount_file_id": "1n5lkrVmivqL9g_NdGYDU5z85aNafzgK-",
      "authorship_tag": "ABX9TyPXxMiAQUj18Ht9wNL2045Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}